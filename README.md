# MONAH
Multi-Modal Narratives for Humans
MONAH creates a multi-modal narrative for dyadic (two-people) video-recorded conversations by weaving _what_ is being said with _how_ its being said.

# ScreenCast
To add later

# Required Inputs
Two videos, one for each speaker. Works best when the camera is in front of the speaker, instead of from an angle.
Verbatim Transcript from YouTube.

# User Interface
Text menu based for easy configuration.

![alt text](https://lucid.app/publicSegments/view/57060778-69b4-4b96-8a6a-2fa7016d2c23/image.jpeg?raw=true)


# Dependencies (Technology Stack)
To add as we build this repo up.
## Fine Narratives
Actions
- OpenFace 2.2.0
https://github.com/TadasBaltrusaitis/OpenFace
  

Prosody
- Vokaturi 3.x
https://developers.vokaturi.com/downloads/sdk
  

## Coarse Narratives
Demographics
- IBM Watson (Deprecated 1 Dec 2021)
https://cloud.ibm.com/docs/personality-insights



# Pipeline (Intermediate Artifacts)
To add later

# Output - MONAH Narrative
To add later

# Continuous Integration
Joshua to add PyLint Python Style Tests
Joshua to add Compulsory Unit Tests
