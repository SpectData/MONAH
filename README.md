# MONAH
Multi-Modal Narratives for Humans
MONAH creates a multi-modal narrative for dyadic (two-people) video-recorded conversations by weaving _what_ is being said with _how_ its being said.

# ScreenCast
To add later

# Required Inputs
Two videos, one for each speaker. Works best when the camera is in front of the speaker, instead of from an angle.

# User Interface
Text menu based for easy configuration.

# Dependencies (Technology Stack)
To add as we build this repo up.
## Fine Narratives
Actions
- OpenFace
Prosody
- Vokaturi

## Coarse Narratives
IBM Watson


# Pipeline (Intermediate Artifacts)
To add later

# Output - MONAH Narrative
To add later

# Continuous Integration
Joshua to add PyLint Python Style Tests
Joshua to add Compulsory Unit Tests
